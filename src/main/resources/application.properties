spring.application.name=PPM_TOOL_SERVICE

spring.datasource.url=jdbc:mysql://localhost:3306/PPMTOOL?createDatabaseIfNotExist=true
spring.datasource.username=root
spring.datasource.password=Sahu@7997
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
# Remove the following line as it is deprecated and not needed
# spring.jpa.database-platform=org.hibernate.dialect.MySQL8Dialect
spring.jpa.hibernate.ddl-auto=update  
spring.jpa.show-sql=true
spring.jpa.properties.hibernate.format_sql=true

server.port=5000

management.endpoints.web.exposure.include=*
management.endpoint.health.show-details=always
management.endpoints.enabled-by-default=true

springfox.documentation.swagger.v2.path=/v2/api-docs
spring.mvc.pathmatch.matching-strategy=ANT_PATH_MATCHER
spring.mvc.throw-exception-if-no-handler-found=true
# spring.mvc.static-path-pattern: /static
spring.mvc.static-path-pattern=/swagger*
spring.resources.add-mappings=false

# Enable Swagger UI
springdoc.swagger-ui.enabled=true
# Base URL for Swagger documentation
springdoc.api-docs.path=/v3/api-docs
# Path to access Swagger UI
springdoc.swagger-ui.path=/swagger-ui.html

# Enable automatic restart (DevTools is enabled by default)
spring.devtools.restart.enabled=true

# Set a longer restart interval if necessary
spring.devtools.restart.poll-interval=500ms

# Disable restart for certain file patterns (e.g., exclude files in 'static' folder)
spring.devtools.restart.exclude=static/**,public/**


##KAFKA_CONFIG


# Kafka Producer Configuration
# Kafka broker address
bootstrap.servers=localhost:9092

# Serializer for the key
key.serializer=org.apache.kafka.common.serialization.StringSerializer

# Serializer for the value
value.serializer=org.apache.kafka.common.serialization.StringSerializer

# Acknowledgement level (0, 1, all)
acks=all

# Producer retries (default is 0)
retries=3

# The maximum size of a request to send to the broker
batch.size=16384

# Buffer memory available to the producer for storing data
buffer.memory=33554432

# The compression type for the message (none, gzip, snappy, lz4, zstd)
compression.type=snappy

# Time to wait for more records before sending a batch (milliseconds)
linger.ms=5
# Kafka Consumer Configuration

# Consumer group ID (each consumer belongs to a group)
#group.id=my-consumer-group

# Deserializer for the key
key.deserializer=org.apache.kafka.common.serialization.StringDeserializer

# Deserializer for the value
value.deserializer=org.apache.kafka.common.serialization.StringDeserializer

# Auto-commit offset (whether consumer commits offsets automatically)
enable.auto.commit=true

# Auto-commit interval (in ms) when enable.auto.commit is true
auto.commit.interval.ms=1000

# The Kafka consumer will start reading from the earliest message
auto.offset.reset=earliest

# The maximum amount of data the consumer will fetch in a single poll
max.partition.fetch.bytes=1048576

# Timeout for a request to the broker to fetch messages
fetch.max.wait.ms=500



#eureka-client
# Eureka client configuration
eureka.client.register-with-eureka=true
eureka.client.fetch-registry=true

# Eureka server URL
eureka.client.service-url.defaultZone=http://localhost:9999/eureka/

# Instance configuration
#eureka.instance.instance-id=${spring.application.name}:${server.port}
#eureka.instance.prefer-ip-address=true